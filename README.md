# README

## Overview

### Project Title
**Analyzing Genetic Sampler Configurations and Performance Against TPE and CMA-ES for Optimizing Random Forest Models in Hyperspectral Soil Analysis**

### Course and Academic Context
This repository hosts the project developed as part of the AIF 24-25 course of the Master's Degree in Computer Science curriculume Artificial Intelligence at the University of Pisa. The work is inspired by a piece of code built for my thesis entitled "The Hyperview Challenge: proposal of a Machine Learning model to improve the state of the art in estimating soil parameters from hyperspectral images" and aims to perform efficiency and effectiveness analyses of the Optuna genetic sampler, thus connecting with the topic of the course "Genetic Algorithms"

### Goal of the Project
The main objective of this project is to analyze the impact of different parameter configurations in the genetic sampler, comparing its performance with other sampling methods provided by Optuna, such as TPE and CMA-ES. For this purpose, the effectiveness and efficiency of a Random Forest model optimized using hyperparameters generated by each sampling method are evaluated. Cross-validation is employed to measure the model's performance. The model will be trained using data provided by the challenge "The Hyperview: Seeing Beyond the Visible," which was the focus of my undergraduate thesis. For more details about the challenge, you can refer to [the official challenge link](https://platform.ai4eo.eu/seeing-beyond-the-visible-permanent).

---

## Features
- **Machine Learning Optimization**: Implements advanced hyperparameter optimization strategies using Optuna.
- **Open-Source Compatibility**: Fully reliant on open-source tools for maximum accessibility.
- **Self-Contained Execution**: Designed to be easily downloaded and run without additional setup complexities.

---

## Repository Structure
```
project-root/
|— data/               # Contains all data files used in the project
|   — raw/            # Raw hyperspectral data as received from sources
|   — processed/      # Preprocessed datasets ready for analysis
|— notebooks/          # Jupyter notebooks for development and experimentation
|   — exploratory/    # Contains notebooks for data exploration and visualization
|   — optimization/   # Notebooks for performing hyperparameter tuning
|— src/                # Source code for the project
|   — models/         # Implementation of machine learning models
|   — samplers/       # Custom genetic sampler and Optuna integration scripts
|— results/            # Stores outputs and logs from experiments
|   — logs/           # Detailed logs of training and optimization processes
|   — comparisons/    # Performance metrics and visualizations for different samplers
|— tests/              # Automated tests to ensure code reliability
|   — unit/           # Unit tests for individual components
|   — integration/    # Tests for the interaction between different parts of the pipeline
|— docs/               # Additional documentation and external references
— README.md            # Project overview (this file)
— requirements.txt     # Python dependencies
— LICENSE              # License information
```

---

## Technologies Used
- **Programming Language**: Python 3.9
- **Libraries and Frameworks**:
  - Optuna (v2.10.0): Hyperparameter optimization
  - Scikit-learn (v0.24.2): Machine learning framework for Random Forest
  - Pandas (v1.3.3) & NumPy (v1.21.2): Data manipulation and analysis
  - Matplotlib (v3.4.3) & Seaborn (v0.11.2): Data visualization
- **Environment**:
  - Jupyter Notebooks
  - Git for version control

---

## Installation
### Prerequisites
1. Ensure Python 3.9 is installed (open-source).
2. Install pip, the Python package manager.
3. For Windows users: Install and configure Windows Subsystem for Linux (WSL2) to create a Linux-based development environment.

### Steps
1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo/hyperview-challenge.git
   cd hyperview-challenge
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Verify the installation:
   ```bash
   python -m unittest discover tests
   ```

---

## Usage
### Data Preparation
1. Place raw hyperspectral data in the `data/raw/` directory.
2. Run preprocessing scripts to generate processed datasets in `data/processed/`. Use the following command for a self-contained execution:
   ```bash
   python src/preprocessing.py --input data/raw/ --output data/processed/
   ```
   Ensure all dependencies are installed from `requirements.txt` to streamline the process for easy setup.
   Example command:
   ```bash
   python src/preprocessing.py --input data/raw/ --output data/processed/
   ```

### Model Training and Optimization
1. Navigate to `notebooks/optimization/`.
2. Run the optimization notebooks to:
   - Configure and execute the genetic sampler.
   - Compare its performance with other Optuna samplers.
3. Results will be saved in the `results/` folder.

### Performance Analysis
1. Use the notebooks in `results/comparisons/` to visualize and interpret performance metrics.

---

## Contribution Guidelines
### Reporting Issues
If you encounter any issues or have suggestions for improvement, please create an issue in the repository. Before opening a new issue, check the existing issues to ensure your concern hasn't already been addressed.

### Pull Requests
1. Fork the repository.
2. Create a feature branch:
   ```bash
   git checkout -b feature/your-feature
   ```
3. Commit your changes and push the branch:
   ```bash
   git push origin feature/your-feature
   ```
4. Open a pull request with a detailed description.

---

## Authors
- **Author**: Alessio Pardini.

---

## License
This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## Contact
For any inquiries or questions, please contact [alessiopardinijob@gmail.com].

