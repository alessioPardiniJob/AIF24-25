# README

## Overview

### Project Title
**Analyzing Genetic Sampler Configurations and Performance Against TPE and CMA-ES for Optimizing Random Forest Models in Hyperspectral Soil Analysis**

### Course and Academic Context
This repository hosts the project developed as part of the AIF 24-25 course of the Master's Degree in Computer Science curriculume Artificial Intelligence at the University of Pisa. The work is inspired by a piece of code built for my thesis entitled "The Hyperview Challenge: proposal of a Machine Learning model to improve the state of the art in estimating soil parameters from hyperspectral images" and aims to perform efficiency and effectiveness analyses of the Optuna genetic sampler, thus connecting with the topic of the course "Genetic Algorithms"

### Goal of the Project
The main objective of this project is to analyze the impact of different parameter configurations in the genetic sampler, comparing its performance with other sampling methods provided by Optuna, such as TPE and CMA-ES. For this purpose, the effectiveness and efficiency of a Random Forest model optimized using hyperparameters generated by each sampling method are evaluated. Cross-validation is employed to measure the model's performance. The model will be trained using data provided by the challenge "The Hyperview: Seeing Beyond the Visible," which was the focus of my undergraduate thesis. For more details about the challenge, you can refer to [the official challenge link](https://platform.ai4eo.eu/seeing-beyond-the-visible-permanent).

---

## Features
- **Machine Learning Optimization**: Implements advanced hyperparameter optimization strategies using Optuna.
- **Open-Source Compatibility**: Fully reliant on open-source tools for maximum accessibility.
- **Self-Contained Execution**: Designed to be easily downloaded and run without additional setup complexities.

---

## Repository Structure
```
project-root/
├── src/                # Core source code for the project
├── data/               # Contains all datasets and data files utilized in the project
├── notebook/           # Jupyter notebooks for development, experimentation, and analysis
├── results/            # Directory for outputs and logs generated from experiments
│   ├── logs/           # Comprehensive logs for training, optimization, and execution processes
│   ├── comparisons/    # Performance metrics, analysis reports, and visualizations for different samplers
├── tests/              # Automated test suite to ensure code quality and reliability
│   ├── unit/           # Unit tests for verifying individual components
│   ├── integration/    # Integration tests for validating the interaction between pipeline components
├── docs/               # Additional project documentation and external references
├── scripts/            # Auxiliary scripts for setup, utilities, and automation
├── requirements.txt    # File listing Python dependencies required for the project
├── Makefile            # Build automation commands and environment setup
├── README.md           # Project overview, setup instructions, and usage guidelines
├── LICENSE             # License details for the project

```

---

## Technologies Used
- **Programming Language**: Python 3.9
- **Libraries and Frameworks**:
  - Optuna (v2.10.0): Hyperparameter optimization
  - Scikit-learn (v0.24.2): Machine learning framework for Random Forest
  - Pandas (v1.3.3) & NumPy (v1.21.2): Data manipulation and analysis
  - Matplotlib (v3.4.3) & Seaborn (v0.11.2): Data visualization
- **Environment**:
  - Jupyter Notebooks
  - Git for version control

---

## Installation
### Prerequisites
1. Ensure Python 3.9 is installed (open-source).
2. Install pip, the Python package manager.
3. For Windows users: Install and configure Windows Subsystem for Linux (WSL2) to create a Linux-based development environment.

### Steps
1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo/hyperview-challenge.git
   cd hyperview-challenge
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Verify the installation:
   ```bash
   python -m unittest discover tests
   ```

---

## Usage
### Data Preparation
1. Place raw hyperspectral data in the `data/raw/` directory.
2. Run preprocessing scripts to generate processed datasets in `data/processed/`. Use the following command for a self-contained execution:
   ```bash
   python src/preprocessing.py --input data/raw/ --output data/processed/
   ```
   Ensure all dependencies are installed from `requirements.txt` to streamline the process for easy setup.
   Example command:
   ```bash
   python src/preprocessing.py --input data/raw/ --output data/processed/
   ```

### Model Training and Optimization
1. Navigate to `notebooks/optimization/`.
2. Run the optimization notebooks to:
   - Configure and execute the genetic sampler.
   - Compare its performance with other Optuna samplers.
3. Results will be saved in the `results/` folder.

### Performance Analysis
1. Use the notebooks in `results/comparisons/` to visualize and interpret performance metrics.

---

## Contribution Guidelines
### Reporting Issues
If you encounter any issues or have suggestions for improvement, please create an issue in the repository. Before opening a new issue, check the existing issues to ensure your concern hasn't already been addressed.

### Pull Requests
1. Fork the repository.
2. Create a feature branch:
   ```bash
   git checkout -b feature/your-feature
   ```
3. Commit your changes and push the branch:
   ```bash
   git push origin feature/your-feature
   ```
4. Open a pull request with a detailed description.

---

## Authors
- **Author**: Alessio Pardini.

---

## License
This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## Contact
For any inquiries or questions, please contact [alessiopardinijob@gmail.com].

